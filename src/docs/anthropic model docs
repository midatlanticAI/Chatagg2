Learn about Claude
Models
Claude is a family of state-of-the-art large language models developed by Anthropic. This guide introduces our models and compares their performance with legacy models.

Claude 3.5 Haiku
Our fastest model


Text input

Text output

200k context window
Claude 3.5 Sonnet
Our most intelligent model


Text and image input

Text output

200k context window
​
Model names
Model	Anthropic API	AWS Bedrock	GCP Vertex AI
Claude 3.5 Sonnet	claude-3-5-sonnet-20241022 (claude-3-5-sonnet-latest)	anthropic.claude-3-5-sonnet-20241022-v2:0	claude-3-5-sonnet-v2@20241022
Claude 3.5 Haiku	claude-3-5-haiku-20241022 (claude-3-5-haiku-latest)	anthropic.claude-3-5-haiku-20241022-v1:0	claude-3-5-haiku@20241022
Model	Anthropic API	AWS Bedrock	GCP Vertex AI
Claude 3 Opus	claude-3-opus-20240229 (claude-3-opus-latest)	anthropic.claude-3-opus-20240229-v1:0	claude-3-opus@20240229
Claude 3 Sonnet	claude-3-sonnet-20240229	anthropic.claude-3-sonnet-20240229-v1:0	claude-3-sonnet@20240229
Claude 3 Haiku	claude-3-haiku-20240307	anthropic.claude-3-haiku-20240307-v1:0	claude-3-haiku@20240307
Models with the same snapshot date (e.g., 20240620) are identical across all platforms and do not change. The snapshot date in the model name ensures consistency and allows developers to rely on stable performance across different environments.
For convenience during development and testing, we offer “-latest” aliases for our models (e.g., claude-3-5-sonnet-latest). These aliases automatically point to the most recent snapshot of a given model. While useful for experimentation, we recommend using specific model versions (e.g., claude-3-5-sonnet-20241022) in production applications to ensure consistent behavior. When we release new model snapshots, we’ll migrate the -latest alias to point to the new version (typically within a week of the new release). The -latest alias is subject to the same rate limits and pricing as the underlying model version it references.

​
Model comparison table
To help you choose the right model for your needs, we’ve compiled a table comparing the key features and capabilities of each model in the Claude family:

Claude 3.5 Sonnet	Claude 3.5 Haiku	Claude 3 Opus	Claude 3 Sonnet	Claude 3 Haiku
Description	Our most intelligent model	Our fastest model	Powerful model for highly complex tasks	Balance of intelligence and speed	Fastest and most compact model for near-instant responsiveness
Strengths	Highest level of intelligence and capability	Intelligence at blazing speeds	Top-level intelligence, fluency, and understanding	Strong utility, balanced for scaled deployments	Quick and accurate targeted performance
Multilingual	Yes	Yes	Yes	Yes	Yes
Vision	Yes	No	Yes	Yes	Yes
Message Batches API	Yes	Yes	Yes	No	Yes
API model name	Upgraded version: claude-3-5-sonnet-20241022

Previous version:claude-3-5-sonnet-20240620	claude-3-5-haiku-20241022	claude-3-opus-20240229	claude-3-sonnet-20240229	claude-3-haiku-20240307
Comparative latency	Fast	Fastest	Moderately fast	Fast	Fastest
Context window	200K	200K	200K	200K	200K
Max output	8192 tokens	8192 tokens	4096 tokens	4096 tokens	4096 tokens
Cost (Input / Output per MTok)	$3.00 / $15.00	$0.80 / $4.00	$15.00 / $75.00	$3.00 / $15.00	$0.25 / $1.25
Training data cut-off	Apr 2024	July 2024	Aug 2023	Aug 2023	Aug 2023
​
Prompt and output performance
The Claude 3.5 family excels in:

​Benchmark performance: Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing. See the Claude 3 model card for more information.

Engaging responses: Claude 3 models are ideal for applications that require rich, human-like interactions.

If you prefer more concise responses, you can adjust your prompts to guide the model toward the desired output length. Refer to our prompt engineering guides for details.
Output quality: When migrating from previous model generations to the Claude 3 family, you may notice larger improvements in overall performance.

​
Legacy models
We recommend migrating to the Claude 3 family of models. However, we understand that some users may need time to transition from our legacy models:

Claude Instant 1.2: A fast and efficient model predecessor of Claude Haiku.
Claude 2.0: The strong-performing predecessor to Claude 3.
Claude 2.1: An updated version of Claude 2 with improved accuracy and consistency.
These models do not have the vision capabilities of the Claude 3 family and are generally slower, less performant and intelligent.

The model deprecation page contains information on when legacy models will be deprecated.

​
Legacy model comparison
To help you choose the right model for your needs, this table compares key features and capabilities.

Claude 2.1	Claude 2	Claude Instant 1.2
Description	Updated version of Claude 2 with improved accuracy	Predecessor to Claude 3, offering strong all-round performance	Our cheapest small and fast model, a predecessor of Claude Haiku
Strengths	Legacy model - performs less well than Claude 3 models	Legacy model - performs less well than Claude 3 models	Legacy model - performs less well than Claude 3 models
Multilingual	Yes, with less coverage, understanding, and skill than Claude 3	Yes, with less coverage, understanding, and skill than Claude 3	Yes, with less coverage, understanding, and skill than Claude 3
Vision	No	No	No
API model name	claude-2.1	claude-2.0	claude-instant-1.2
API format	Messages & Text Completions API	Messages & Text Completions API	Messages & Text Completions API
Comparative latency	Slower than Claude 3 model of similar intelligence	Slower than Claude 3 model of similar intelligence	Slower than Claude 3 model of similar intelligence
Context window	200K	100K	100K
Max output	4096 tokens	4096 tokens	4096 tokens
Cost (Input / Output per MTok)	$8.00 / $24.00	$8.00 / $24.00	$0.80 / $2.40
Training data cut-off	Early 2023	Early 2023	Early 2023